{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 08. Multi Layer Perceptron\n",
    "\n",
    "과제는 총 3개의 cell을 작성하도록 구성되어있습니다\n",
    "\n",
    "1~3 문제는 영상과 실습자료에 나와있는 것들을 적절히 응용하시면 됩니다\n",
    "\n",
    "주석의 경우 이미지, 테이블 등의 표현이 어려운 관계로 받지 않겠습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 00. Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset covertype이며, 인공위성이 찍은 사진을 전처리하여 table data로 작성한 dataset입니다\n",
    "\n",
    "train set으로 다양한 방법들을 교차검증하고, test set에서도 좋은 성능을 보이는지 확인해보겠습니다\n",
    "\n",
    "train set과 test set을 불러와주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly import graph_objs as go\n",
    "\n",
    "\n",
    "x_train=pd.read_csv('08_mlp_x_train.csv')\n",
    "x_test=pd.read_csv('08_mlp_x_test.csv')\n",
    "y_train=pd.read_csv('08_mlp_y_train.csv')\n",
    "y_test=pd.read_csv('08_mlp_y_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 01. K-Fold validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train set으로부터 학습된 모델은 test set을 잘 예측해야 하는 목표를 갖고 있습니다\n",
    "\n",
    "test을 잘 예측하기 위해 각 방법별로 교차검증을 시도하겠습니다\n",
    "\n",
    "모든 train sample들에 평균적으로 가장 좋은 성능을 보이는 모델을 찾아보려합니다\n",
    "\n",
    "다음 방법들을 5-Fold를 사용하여 교차검증해주세요\n",
    "\n",
    "그리고 실제 test set에 대해 성능을 마지막으로 출력해주세요\n",
    "\n",
    "사용할 분류 기법 : Gaussian Naive-bayes, k-Neighbors Nearest, Decision Tree, Random Forest, Logistics regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf=KFold(shuffle=True)\n",
    "\n",
    "test_index_set=set()\n",
    "\n",
    "x=x_train\n",
    "y=y_train\n",
    "\n",
    "for train_index, test_index in kf.split(x_train, y_train):\n",
    "    test_index_set.update(test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. KNeighborsClassifier 평균 정확도 : 97.185%, 정확도의 편차 : 0.00163\n",
      "2. DecisionTreeClassifier 평균 정확도 : 93.799%, 정확도의 편차 : 0.00174\n",
      "3. LogisticRegression 평균 정확도 : 72.496%, 정확도의 편차 : 0.00349\n",
      "4. GaussianNB 평균 정확도 : 71.505%, 정확도의 편차 : 0.00481\n",
      "5. RandomForestClassifier 평균 정확도 : 95.739%, 정확도의 편차 : 0.00285\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "KNN_scores=[]\n",
    "DT_scores=[]\n",
    "Logistic_scores=[]\n",
    "GNB_scores=[]\n",
    "RF_scores=[]\n",
    "\n",
    "KNN=KNeighborsClassifier()\n",
    "DT=DecisionTreeClassifier()\n",
    "logistic=LogisticRegression(max_iter=100)\n",
    "GNB=GaussianNB()\n",
    "RF=RandomForestClassifier()\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test=\\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    KNN.fit(x_train, y_train.values.ravel())\n",
    "    DT.fit(x_train, y_train.values.ravel())\n",
    "    logistic.fit(x_train, y_train.values.ravel())\n",
    "    GNB.fit(x_train, y_train.values.ravel())\n",
    "    RF.fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    KNN_scores.append(KNN.score(x_test, y_test.values.ravel()))\n",
    "    DT_scores.append(DT.score(x_test, y_test.values.ravel()))\n",
    "    Logistic_scores.append(logistic.score(x_test, y_test.values.ravel()))\n",
    "    GNB_scores.append(GNB.score(x_test, y_test.values.ravel()))\n",
    "    RF_scores.append(RF.score(x_test, y_test.values.ravel()))\n",
    "\n",
    "print(f'1. KNeighborsClassifier 평균 정확도 : {np.array(KNN_scores).mean()*100:.5}%, 정확도의 편차 : {np.array(KNN_scores).std():.3}')\n",
    "print(f'2. DecisionTreeClassifier 평균 정확도 : {np.array(DT_scores).mean()*100:.5}%, 정확도의 편차 : {np.array(DT_scores).std():.3}')\n",
    "print(f'3. LogisticRegression 평균 정확도 : {np.array(Logistic_scores).mean()*100:.5}%, 정확도의 편차 : {np.array(Logistic_scores).std():.3}')\n",
    "print(f'4. GaussianNB 평균 정확도 : {np.array(GNB_scores).mean()*100:.5}%, 정확도의 편차 : {np.array(GNB_scores).std():.3}')\n",
    "print(f'5. RandomForestClassifier 평균 정확도 : {np.array(RF_scores).mean()*100:.5}%, 정확도의 편차 : {np.array(RF_scores).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실습 02. Multi Layer Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP는 perceptron들을 다양한 구조로 엮어놓은 모델입니다\n",
    "\n",
    "Perceptron의 layer 갯수와 각 층마다 존재하는 perceptorn의 갯수, perceptron의 output을 변형하는 함수등이 모델성능을 결정합니다\n",
    "\n",
    "실습영상에서는 perceptron의 층수만 바꿔가며 간단하게 실험하였지만 과제로 다양한 MLP 모델을 시도해보겠습니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 02-1. Multi Layer Perceptron - The number of perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perceptron의 갯수를 감소시켜가며 확인해보겠습니다\n",
    "\n",
    "2개의 perceptron layer를 사용하면서 50개, 20개일때로 층별 perceptron의 숫자를 줄여보세요\n",
    "\n",
    "그리고 2개의 모델을 5-fold로 교차검증하여 아래 결과를 제시해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1) 각 layer의 perceptron 수가 50인 모델의 score :  [0.7140275581658008, 0.695617799864468, 0.7431379193493731, 0.6859821529425054, 0.6502880379532362]\n",
      "\n",
      "1-2) 각 layer의 perceptron 수가 50인 모델의 평균 정확도: 69.781%, 정확도의 편차 : 0.0307\n",
      "\n",
      "\n",
      "2-1) 각 layer의 perceptron 수가 20인 모델의 score :  [0.6881635419019652, 0.7117686921165575, 0.7232576527730713, 0.7173839376482548, 0.7342143906020558]\n",
      "\n",
      "2-2) 각 layer의 perceptron 수가 20인 모델의 평균 정확도: 71.496%, 정확도의 편차 : 0.0153\n",
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlp1=MLPClassifier((50,50),\n",
    "                 activation='identity',\n",
    "                 max_iter=200,\n",
    "                 n_iter_no_change=10,\n",
    "                 )\n",
    "\n",
    "mlp2=MLPClassifier((20,20),\n",
    "                 activation='identity',\n",
    "                 max_iter=200,\n",
    "                 n_iter_no_change=10,\n",
    "                 )\n",
    "\n",
    "scores1=[]\n",
    "scores2=[]\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test=\\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlp1.fit(x_train, y_train.values.ravel())\n",
    "    mlp2.fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    scores1.append(mlp1.score(x_test, y_test.values.ravel()))\n",
    "    scores2.append(mlp2.score(x_test, y_test.values.ravel()))\n",
    "\n",
    "print('1-1) 각 layer의 perceptron 수가 50인 모델의 score : ', scores1)\n",
    "print(f'\\n1-2) 각 layer의 perceptron 수가 50인 모델의 평균 정확도: {np.array(scores1).mean()*100:.5}%, 정확도의 편차 : {np.array(scores1).std():.3}\\n\\n')\n",
    "print('2-1) 각 layer의 perceptron 수가 20인 모델의 score : ', scores2)\n",
    "print(f'\\n2-2) 각 layer의 perceptron 수가 20인 모델의 평균 정확도: {np.array(scores2).mean()*100:.5}%, 정확도의 편차 : {np.array(scores2).std():.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 실습 02-1. Multi Layer Perceptron - Various output function for every perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실습 영상에서 사용한 MLP는 각 perceptron output function으로 $f(x)=x$의 관계인 linear output을 사용하고 있습니다\n",
    "\n",
    "이번에는 linear output을 바꿔 sigmoid를 사용해보겠습니다\n",
    "\n",
    "MLP classifier의 activations parameter를 'identity'에서 'logistic' 또는 'tanh'로 바꿔주세요\n",
    "\n",
    "그리고 실습 02-1.의 과정을 반복하여 결과를 제시해주세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-1) 기존 모델의 score :  [0.7394398012197877, 0.7304043370228146, 0.4962159719868971, 0.6708460408900938, 0.5866937761210889]\n",
      "\n",
      "1-2) 기존 모델의 평균 정확도: 64.472%, 정확도의 편차 : 0.0921\n",
      "\n",
      "\n",
      "2-1) activations parameter=logistic인 모델의 score :  [0.7977185452902643, 0.7680144567427152, 0.7922738054896645, 0.7941940585112391, 0.8079746978425393]\n",
      "\n",
      "2-2) activations parameter=logistic인 모델의 평균 정확도: 79.204%, 정확도의 편차 : 0.0132\n",
      "\n",
      "\n",
      "3-1) activations parameter=tanh인 모델의 score :  [0.7388750847074769, 0.7648520442737745, 0.7734101434541963, 0.7554501298994691, 0.7369253360442788]\n",
      "\n",
      "3-2) activations parameter=tanh인 모델의 평균 정확도: 75.39%, 정확도의 편차 : 0.0143\n",
      "Wall time: 4min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "mlp1=MLPClassifier((100,),\n",
    "                 activation='identity',\n",
    "                 max_iter=200,\n",
    "                 n_iter_no_change=10,\n",
    "                 )\n",
    "\n",
    "mlp2=MLPClassifier((100,),\n",
    "                 activation='logistic',\n",
    "                 max_iter=200,\n",
    "                 n_iter_no_change=10,\n",
    "                 )\n",
    "\n",
    "mlp3=MLPClassifier((100,),\n",
    "                 activation='tanh',\n",
    "                 max_iter=200,\n",
    "                 n_iter_no_change=10,\n",
    "                 )\n",
    "\n",
    "scores1=[]\n",
    "scores2=[]\n",
    "scores3=[]\n",
    "\n",
    "for train_index, test_index in kf.split(x, y):\n",
    "    x_train, x_test, y_train, y_test=\\\n",
    "    x.iloc[train_index], x.iloc[test_index], y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    mlp1.fit(x_train, y_train.values.ravel())\n",
    "    mlp2.fit(x_train, y_train.values.ravel())\n",
    "    mlp3.fit(x_train, y_train.values.ravel())\n",
    "    \n",
    "    scores1.append(mlp1.score(x_test, y_test.values.ravel()))\n",
    "    scores2.append(mlp2.score(x_test, y_test.values.ravel()))\n",
    "    scores3.append(mlp3.score(x_test, y_test.values.ravel()))\n",
    "\n",
    "print('1-1) 기존 모델의 score : ', scores1)\n",
    "print(f'\\n1-2) 기존 모델의 평균 정확도: {np.array(scores1).mean()*100:.5}%, 정확도의 편차 : {np.array(scores1).std():.3}\\n\\n')\n",
    "print('2-1) activations parameter=logistic인 모델의 score : ', scores2)\n",
    "print(f'\\n2-2) activations parameter=logistic인 모델의 평균 정확도: {np.array(scores2).mean()*100:.5}%, 정확도의 편차 : {np.array(scores2).std():.3}\\n\\n')\n",
    "print('3-1) activations parameter=tanh인 모델의 score : ', scores3)\n",
    "print(f'\\n3-2) activations parameter=tanh인 모델의 평균 정확도: {np.array(scores3).mean()*100:.5}%, 정확도의 편차 : {np.array(scores3).std():.3}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
